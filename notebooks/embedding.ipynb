{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"always\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "sns.set_theme(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:39:42.309672: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 02:39:42.309748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 02:39:42.341172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 02:39:42.425184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 02:39:43.592768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# stop-words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "# tokenizing\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_1 = \"bitty bought a bit of butter\"\n",
    "sample_text_2 = \"but the bit of butter was a bit bitter\"\n",
    "sample_text_3 = \"so she bought some better butter to make the bitter butter better\"\n",
    "\n",
    "corp = [sample_text_1, sample_text_2, sample_text_3]\n",
    "no_docs = len(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for document 1  is :  [1, 48, 1, 12, 26, 43]\n",
      "The encoding for document 2  is :  [13, 4, 12, 26, 43, 15, 1, 12, 45]\n",
      "The encoding for document 3  is :  [45, 21, 48, 20, 20, 43, 43, 15, 4, 45, 43, 20]\n"
     ]
    }
   ],
   "source": [
    "# INTEGER ENCODING ALL THE DOCUMENTS\n",
    "\n",
    "vocab_size = 50  #  the vocab_size is specified large enough so as to ensure unique integer encoding for each and every word.\n",
    "encode_corp = []\n",
    "\n",
    "for i, doc in enumerate(corp):\n",
    "    encode_corp.append(one_hot(doc, 50))\n",
    "    print(\"The encoding for document\", i + 1, \" is : \", one_hot(doc, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bitty', 'bought', 'a', 'bit', 'of', 'butter']\n",
      "['but', 'the', 'bit', 'of', 'butter', 'was', 'a', 'bit', 'bitter']\n",
      "['so', 'she', 'bought', 'some', 'better', 'butter', 'to', 'make', 'the', 'bitter', 'butter', 'better']\n",
      "The Maximum number of words in any document is :  12\n"
     ]
    }
   ],
   "source": [
    "# PADDING THE DOCS (to make very doc of same length)\n",
    "\n",
    "# The Keras Embedding layer requires all individual documents to be of same length\n",
    "# Hence we wil pad the shorter documents with 0 for now.\n",
    "# Therefore now in Keras Embedding layer the 'input_length' will be equal to the length (ie no of words) of the document\n",
    "# with maximum length or maximum number of words.\n",
    "# To pad the shorter documents I am using pad_sequences functon from the Keras library.\n",
    "\n",
    "\n",
    "maxlen = -1\n",
    "for doc in corp:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    print(tokens)\n",
    "    if maxlen < len(tokens):\n",
    "        maxlen = len(tokens)\n",
    "\n",
    "print(\"The Maximum number of words in any document is : \", maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of padded documents:  3\n",
      "The padded encoding for document 1  is :  [ 1 48  1 12 26 43  0  0  0  0  0  0]\n",
      "The padded encoding for document 2  is :  [13  4 12 26 43 15  1 12 45  0  0  0]\n",
      "The padded encoding for document 3  is :  [45 21 48 20 20 43 43 15  4 45 43 20]\n"
     ]
    }
   ],
   "source": [
    "# now to create embeddings all of our docs need to be of same length. hence we can pad the docs with zeros.\n",
    "pad_corp = pad_sequences(encode_corp, maxlen=maxlen, padding=\"post\", value=0.0)\n",
    "print(\"No of padded documents: \", len(pad_corp))\n",
    "for i, doc in enumerate(pad_corp):\n",
    "    print(\"The padded encoding for document\", i + 1, \" is : \", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all the documents are of same length (after padding). And so now we are ready to create and use the embeddings.\n",
    "inputs = Input(shape=(no_docs, maxlen), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 02:58:22.655492: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.799111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.799359: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.801139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.801385: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.801584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.992451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.992838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.992888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-10-04 02:58:22.993214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 02:58:22.993271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9536 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:26:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "shape of input. \n",
    "each document has 12 element or words which is the value of our maxlen variable.\n",
    "\"\"\"\n",
    "\n",
    "word_input = Input(shape=(maxlen,), dtype=\"float32\")\n",
    "\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=8, input_length=maxlen)(\n",
    "    word_input\n",
    ")\n",
    "\n",
    "word_vec = Flatten()(word_embedding)\n",
    "\n",
    "embed_model = Model([word_input], word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS OF THE EMBEDDING LAYER ---\n",
    "\n",
    "'input_dim' = the vocab size that we will choose. In other words it is the number of unique words in the vocab.\n",
    "\n",
    "'output_dim' = the number of dimensions we wish to embed into. Each word will be represented by a vector of this much dimensions.\n",
    "\n",
    "'input_length' = lenght of the maximum document. which is stored in maxlen variable in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.keras_tensor.KerasTensor'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 12, 8), dtype=tf.float32, name=None), name='embedding/embedding_lookup/Identity:0', description=\"created by layer 'embedding'\")\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 12)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 12, 8)             400       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 400 (1.56 KB)\n",
      "Trainable params: 400 (1.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embed_model.summary())  # summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_model.predict(pad_corp)  # finally getting the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 96)\n",
      "[[ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381   0.02427639\n",
      "   0.03229351 -0.01415057 -0.01682829  0.00953909  0.04553615  0.02884376\n",
      "  -0.00994335  0.04756803 -0.0150812  -0.0140302   0.03554154 -0.03450155\n",
      "   0.00236611  0.02651289  0.0381381   0.02427639  0.03229351 -0.01415057\n",
      "   0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766  0.03916797\n",
      "   0.02353359 -0.03656213 -0.02294981 -0.00203184 -0.00591069 -0.02385206\n",
      "   0.03165257  0.02598954 -0.00122378 -0.02945955  0.00985926 -0.03045031\n",
      "  -0.00322922 -0.02833431  0.00508649  0.0366048   0.04135503  0.00198681\n",
      "   0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "   0.01267872 -0.03109838  0.01818998  0.00220318  0.03916449  0.01319063\n",
      "   0.04604201  0.02142968  0.01267872 -0.03109838  0.01818998  0.00220318\n",
      "   0.03916449  0.01319063  0.04604201  0.02142968  0.01267872 -0.03109838\n",
      "   0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "   0.01267872 -0.03109838  0.01818998  0.00220318  0.03916449  0.01319063\n",
      "   0.04604201  0.02142968  0.01267872 -0.03109838  0.01818998  0.00220318\n",
      "   0.03916449  0.01319063  0.04604201  0.02142968  0.01267872 -0.03109838]\n",
      " [ 0.03442539 -0.02089676 -0.02427598 -0.02220361 -0.04343628  0.00023985\n",
      "   0.01584772 -0.0157614  -0.01645962 -0.00387052  0.01820794  0.04380286\n",
      "  -0.03338257  0.02335301 -0.00040331 -0.00553042  0.04744269  0.01025765\n",
      "  -0.00566924 -0.00685807 -0.02889766  0.03916797  0.02353359 -0.03656213\n",
      "  -0.02294981 -0.00203184 -0.00591069 -0.02385206  0.03165257  0.02598954\n",
      "  -0.00122378 -0.02945955  0.00985926 -0.03045031 -0.00322922 -0.02833431\n",
      "   0.00508649  0.0366048   0.04135503  0.00198681  0.01736246  0.04479662\n",
      "   0.00172476 -0.04144342 -0.02711064 -0.03027544  0.00689952  0.01728704\n",
      "   0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381   0.02427639\n",
      "   0.03229351 -0.01415057  0.04744269  0.01025765 -0.00566924 -0.00685807\n",
      "  -0.02889766  0.03916797  0.02353359 -0.03656213  0.03359452  0.03930039\n",
      "  -0.01870761 -0.00780278 -0.04317179  0.04860345 -0.02146666  0.01454394\n",
      "   0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "   0.01267872 -0.03109838  0.01818998  0.00220318  0.03916449  0.01319063\n",
      "   0.04604201  0.02142968  0.01267872 -0.03109838  0.01818998  0.00220318\n",
      "   0.03916449  0.01319063  0.04604201  0.02142968  0.01267872 -0.03109838]\n",
      " [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179  0.04860345\n",
      "  -0.02146666  0.01454394  0.00587771 -0.03800379  0.03067508  0.0334943\n",
      "  -0.00786682  0.02690757 -0.03917167 -0.02306668 -0.01682829  0.00953909\n",
      "   0.04553615  0.02884376 -0.00994335  0.04756803 -0.0150812  -0.0140302\n",
      "  -0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952  0.0162514\n",
      "  -0.02983692  0.02335873 -0.02245698  0.03673809  0.00316298 -0.04542822\n",
      "  -0.04533952  0.0162514  -0.02983692  0.02335873  0.00985926 -0.03045031\n",
      "  -0.00322922 -0.02833431  0.00508649  0.0366048   0.04135503  0.00198681\n",
      "   0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "   0.04135503  0.00198681  0.01736246  0.04479662  0.00172476 -0.04144342\n",
      "  -0.02711064 -0.03027544  0.00689952  0.01728704 -0.01645962 -0.00387052\n",
      "   0.01820794  0.04380286 -0.03338257  0.02335301 -0.00040331 -0.00553042\n",
      "   0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179  0.04860345\n",
      "  -0.02146666  0.01454394  0.00985926 -0.03045031 -0.00322922 -0.02833431\n",
      "   0.00508649  0.0366048   0.04135503  0.00198681 -0.02245698  0.03673809\n",
      "   0.00316298 -0.04542822 -0.04533952  0.0162514  -0.02983692  0.02335873]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of embeddings : \", embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 12, 8)\n",
      "[[[ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381\n",
      "    0.02427639  0.03229351 -0.01415057]\n",
      "  [-0.01682829  0.00953909  0.04553615  0.02884376 -0.00994335\n",
      "    0.04756803 -0.0150812  -0.0140302 ]\n",
      "  [ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381\n",
      "    0.02427639  0.03229351 -0.01415057]\n",
      "  [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766\n",
      "    0.03916797  0.02353359 -0.03656213]\n",
      "  [-0.02294981 -0.00203184 -0.00591069 -0.02385206  0.03165257\n",
      "    0.02598954 -0.00122378 -0.02945955]\n",
      "  [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649\n",
      "    0.0366048   0.04135503  0.00198681]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]]\n",
      "\n",
      " [[ 0.03442539 -0.02089676 -0.02427598 -0.02220361 -0.04343628\n",
      "    0.00023985  0.01584772 -0.0157614 ]\n",
      "  [-0.01645962 -0.00387052  0.01820794  0.04380286 -0.03338257\n",
      "    0.02335301 -0.00040331 -0.00553042]\n",
      "  [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766\n",
      "    0.03916797  0.02353359 -0.03656213]\n",
      "  [-0.02294981 -0.00203184 -0.00591069 -0.02385206  0.03165257\n",
      "    0.02598954 -0.00122378 -0.02945955]\n",
      "  [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649\n",
      "    0.0366048   0.04135503  0.00198681]\n",
      "  [ 0.01736246  0.04479662  0.00172476 -0.04144342 -0.02711064\n",
      "   -0.03027544  0.00689952  0.01728704]\n",
      "  [ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381\n",
      "    0.02427639  0.03229351 -0.01415057]\n",
      "  [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766\n",
      "    0.03916797  0.02353359 -0.03656213]\n",
      "  [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179\n",
      "    0.04860345 -0.02146666  0.01454394]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]\n",
      "  [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201\n",
      "    0.02142968  0.01267872 -0.03109838]]\n",
      "\n",
      " [[ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179\n",
      "    0.04860345 -0.02146666  0.01454394]\n",
      "  [ 0.00587771 -0.03800379  0.03067508  0.0334943  -0.00786682\n",
      "    0.02690757 -0.03917167 -0.02306668]\n",
      "  [-0.01682829  0.00953909  0.04553615  0.02884376 -0.00994335\n",
      "    0.04756803 -0.0150812  -0.0140302 ]\n",
      "  [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952\n",
      "    0.0162514  -0.02983692  0.02335873]\n",
      "  [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952\n",
      "    0.0162514  -0.02983692  0.02335873]\n",
      "  [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649\n",
      "    0.0366048   0.04135503  0.00198681]\n",
      "  [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649\n",
      "    0.0366048   0.04135503  0.00198681]\n",
      "  [ 0.01736246  0.04479662  0.00172476 -0.04144342 -0.02711064\n",
      "   -0.03027544  0.00689952  0.01728704]\n",
      "  [-0.01645962 -0.00387052  0.01820794  0.04380286 -0.03338257\n",
      "    0.02335301 -0.00040331 -0.00553042]\n",
      "  [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179\n",
      "    0.04860345 -0.02146666  0.01454394]\n",
      "  [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649\n",
      "    0.0366048   0.04135503  0.00198681]\n",
      "  [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952\n",
      "    0.0162514  -0.02983692  0.02335873]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings.reshape(-1, maxlen, 8)\n",
    "print(\"Shape of embeddings : \", embeddings.shape)\n",
    "print(embeddings)\n",
    "\n",
    "# The resulting shape is (3,12,8).\n",
    "\n",
    "# 3---> no of documents\n",
    "\n",
    "# 12---> each document is made of 12 words which was our maximum length of any document.\n",
    "\n",
    "# & 8---> each word is 8 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for  1 th word in 1 th document is : \n",
      "\n",
      " [ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381   0.02427639\n",
      "  0.03229351 -0.01415057]\n",
      "The encoding for  2 th word in 1 th document is : \n",
      "\n",
      " [-0.01682829  0.00953909  0.04553615  0.02884376 -0.00994335  0.04756803\n",
      " -0.0150812  -0.0140302 ]\n",
      "The encoding for  3 th word in 1 th document is : \n",
      "\n",
      " [ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381   0.02427639\n",
      "  0.03229351 -0.01415057]\n",
      "The encoding for  4 th word in 1 th document is : \n",
      "\n",
      " [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766  0.03916797\n",
      "  0.02353359 -0.03656213]\n",
      "The encoding for  5 th word in 1 th document is : \n",
      "\n",
      " [-0.02294981 -0.00203184 -0.00591069 -0.02385206  0.03165257  0.02598954\n",
      " -0.00122378 -0.02945955]\n",
      "The encoding for  6 th word in 1 th document is : \n",
      "\n",
      " [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "  0.04135503  0.00198681]\n",
      "The encoding for  7 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  8 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  9 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  10 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  11 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  12 th word in 1 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  1 th word in 2 th document is : \n",
      "\n",
      " [ 0.03442539 -0.02089676 -0.02427598 -0.02220361 -0.04343628  0.00023985\n",
      "  0.01584772 -0.0157614 ]\n",
      "The encoding for  2 th word in 2 th document is : \n",
      "\n",
      " [-0.01645962 -0.00387052  0.01820794  0.04380286 -0.03338257  0.02335301\n",
      " -0.00040331 -0.00553042]\n",
      "The encoding for  3 th word in 2 th document is : \n",
      "\n",
      " [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766  0.03916797\n",
      "  0.02353359 -0.03656213]\n",
      "The encoding for  4 th word in 2 th document is : \n",
      "\n",
      " [-0.02294981 -0.00203184 -0.00591069 -0.02385206  0.03165257  0.02598954\n",
      " -0.00122378 -0.02945955]\n",
      "The encoding for  5 th word in 2 th document is : \n",
      "\n",
      " [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "  0.04135503  0.00198681]\n",
      "The encoding for  6 th word in 2 th document is : \n",
      "\n",
      " [ 0.01736246  0.04479662  0.00172476 -0.04144342 -0.02711064 -0.03027544\n",
      "  0.00689952  0.01728704]\n",
      "The encoding for  7 th word in 2 th document is : \n",
      "\n",
      " [ 0.03554154 -0.03450155  0.00236611  0.02651289  0.0381381   0.02427639\n",
      "  0.03229351 -0.01415057]\n",
      "The encoding for  8 th word in 2 th document is : \n",
      "\n",
      " [ 0.04744269  0.01025765 -0.00566924 -0.00685807 -0.02889766  0.03916797\n",
      "  0.02353359 -0.03656213]\n",
      "The encoding for  9 th word in 2 th document is : \n",
      "\n",
      " [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179  0.04860345\n",
      " -0.02146666  0.01454394]\n",
      "The encoding for  10 th word in 2 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  11 th word in 2 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  12 th word in 2 th document is : \n",
      "\n",
      " [ 0.01818998  0.00220318  0.03916449  0.01319063  0.04604201  0.02142968\n",
      "  0.01267872 -0.03109838]\n",
      "The encoding for  1 th word in 3 th document is : \n",
      "\n",
      " [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179  0.04860345\n",
      " -0.02146666  0.01454394]\n",
      "The encoding for  2 th word in 3 th document is : \n",
      "\n",
      " [ 0.00587771 -0.03800379  0.03067508  0.0334943  -0.00786682  0.02690757\n",
      " -0.03917167 -0.02306668]\n",
      "The encoding for  3 th word in 3 th document is : \n",
      "\n",
      " [-0.01682829  0.00953909  0.04553615  0.02884376 -0.00994335  0.04756803\n",
      " -0.0150812  -0.0140302 ]\n",
      "The encoding for  4 th word in 3 th document is : \n",
      "\n",
      " [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952  0.0162514\n",
      " -0.02983692  0.02335873]\n",
      "The encoding for  5 th word in 3 th document is : \n",
      "\n",
      " [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952  0.0162514\n",
      " -0.02983692  0.02335873]\n",
      "The encoding for  6 th word in 3 th document is : \n",
      "\n",
      " [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "  0.04135503  0.00198681]\n",
      "The encoding for  7 th word in 3 th document is : \n",
      "\n",
      " [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "  0.04135503  0.00198681]\n",
      "The encoding for  8 th word in 3 th document is : \n",
      "\n",
      " [ 0.01736246  0.04479662  0.00172476 -0.04144342 -0.02711064 -0.03027544\n",
      "  0.00689952  0.01728704]\n",
      "The encoding for  9 th word in 3 th document is : \n",
      "\n",
      " [-0.01645962 -0.00387052  0.01820794  0.04380286 -0.03338257  0.02335301\n",
      " -0.00040331 -0.00553042]\n",
      "The encoding for  10 th word in 3 th document is : \n",
      "\n",
      " [ 0.03359452  0.03930039 -0.01870761 -0.00780278 -0.04317179  0.04860345\n",
      " -0.02146666  0.01454394]\n",
      "The encoding for  11 th word in 3 th document is : \n",
      "\n",
      " [ 0.00985926 -0.03045031 -0.00322922 -0.02833431  0.00508649  0.0366048\n",
      "  0.04135503  0.00198681]\n",
      "The encoding for  12 th word in 3 th document is : \n",
      "\n",
      " [-0.02245698  0.03673809  0.00316298 -0.04542822 -0.04533952  0.0162514\n",
      " -0.02983692  0.02335873]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(embeddings):\n",
    "    for j, word in enumerate(doc):\n",
    "        print(\n",
    "            \"The encoding for \",\n",
    "            j + 1,\n",
    "            \"th word\",\n",
    "            \"in\",\n",
    "            i + 1,\n",
    "            \"th document is : \\n\\n\",\n",
    "            word,\n",
    "        )\n",
    "\n",
    "# Now this makes it easier to visualize that we have 3(size of corp) documents with each consisting of 12(maxlen) words\n",
    "# and each word mapped to a 8-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
